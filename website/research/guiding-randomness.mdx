---
title: "Guiding randomness"
slug: "guiding-randomness"
publishedAt: "2025-09-05"
summary: "Chat UIs are a slight of hand"
subhead: ""
draft: true
---

LLMs are random token generators

The slight of hand with chat ui is that you are collaboratively providing tokens and receiving the next plausiable tokens but it gets masked as a conversation. if you use words like doc or code snippet it is able to structure its responses into those forms

a logical trick of you asked and it responds. but they hide the fact that the response you receive is not the sole response. the edges get sanded down and authority can easily be amplified in the source of links even if those links and sources and justifications were hallucinations

what if the ui supported/leaned into this quality of endless generation. if these machines are randomness then randomness should be the grain (Robin Sloan) that we should design around

DEMO: send a chat and get 5 responses that you have to select one to continue the chat
